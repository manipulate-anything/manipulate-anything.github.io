<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>Manipulate Anything</title>
    <meta name="description" content="Manipulate-Anything: Automating Real-World Robots using Vision-Language Models">
    <meta name="keywords" content="Zero-shot manipulation, Multimodal language models">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

    <style type="text/css">
        #simulation-result-video {
            width: 50%;
            height: auto;
        }
        #peract-simulation-result-video {
            width: 75%;
            height: auto;
        }
    </style>

    <script>
        function init() {
            const video = document.getElementById("simulation-result-video");
            video.addEventListener("error", () => {
                console.log("Error loading video: ", video.src), ". Setting default to none";
                if(video.src.includes("undefined")) {
                    console.log("Don't have an undefined version of the clip, just crash");
                    return;
                }
                const method = document.getElementById("single-menu-methods").value;
                const uri = "static/videos/simulation/" + method + "/undefined.mp4"
                video.src = uri;
                video.playbackRate = 1.75;
                video.play();
            }, true);

            const video_peract = document.getElementById("peract-simulation-result-video");
            video_peract.addEventListener("error", () => {
                console.log("Error loading video: ", video_peract.src), ". Setting default to none";
                if(video_peract.src.includes("undefined")) {
                    console.log("Don't have an undefined version of the clip, just crash");
                    return;
                }
                const method = document.getElementById("peract-single-menu-methods").value;
                const uri = "static/videos/simulation_peract/" + method + "/undefined.mp4"
                video_peract.src = uri;
                video_peract.playbackRate = 1.75;
                video_peract.play();
            }, true);
        }
        function updateSimulationGeneratedDataVideo() {
            const task = document.getElementById("single-menu-tasks").value;
            const method = document.getElementById("single-menu-methods").value;
            const video = document.getElementById("simulation-result-video");
            const uri = "static/videos/simulation/" + method + "/" + task + ".mp4"
            video.src = uri;
            video.playbackRate = 1.75;
            video.play();
        }
        function updatePerActTrainedVideo() {
            const task = document.getElementById("peract-single-menu-tasks").value;
            const method = document.getElementById("peract-single-menu-methods").value;
            const video = document.getElementById("peract-simulation-result-video");
            const uri = "static/videos/simulation_peract/" + method + "/" + task + ".mp4"
            video.src = uri;
            video.playbackRate = 1.75;
            video.play();

        }
    </script>
</head>

<body onload="init(); updateSimulationGeneratedDataVideo();">
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">
                            Manipulate-Anything: <br> Automating Real-World Robots using Vision-Language Models
                        </h1>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <!-- Video teaser -->
                <video id="teaser" autoplay muted loop height="100">
                    <source src="static/videos/video_teaser.mp4" type="video/mp4">
                </video>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Large-scale endeavors like RT-1 and widespread community efforts
                            such as Open-X-Embodiment have contributed to growing the scale of robot
                            demonstration data. However, there is still an opportunity to improve the quality,
                            quantity, and diversity of robot demonstration data. Although vision-language
                            models have been shown to automatically generate demonstration data, their utility
                            has been limited to environments with privileged state information, they require
                            hand-designed skills, and are limited to interactions with few object instances. We
                            propose MANIPULATE-ANYTHING, a scalable automated generation method for
                            real-world robotic manipulation. Unlike prior work, our method can operate in
                            real-world environments without any privileged state information, hand-designed
                            skills, and can manipulate any static object. We evaluate our method using two
                            setups. First, MANIPULATE-ANYTHING successfully generates trajectories for all
                            5 real-world and 12 simulation tasks, significantly outperforming existing methods
                            like VoxPoser. Second, MANIPULATE-ANYTHINGâ€™s demonstrations can train
                            more robust behavior cloning policies than training with human demonstrations,
                            or from data generated by VoxPoser and Code-As-Policies. We believe
                            MANIPULATE-ANYTHING can be the scalable method for both generating data for
                            robotics and solving novel tasks in a zero-shot setting.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->
        </div>
    </section>

    <!-- Real-world Results -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <h2 class="title is-3">Real World Results</h2>
                <div class="column has-text-centered">
                    <h3 class="title is-5">Manipulate-Anything</h3>
                </div>
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-steve">
                        <video id="steve" autoplay muted loop>
                            <source src="static/videos/real_world/Turn_on_lamp_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-fullbody">
                        <video id="fullbody" autoplay muted loop>
                            <source src="static/videos/real_world/open_drawer_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-shiba">
                        <video id="shiba" autoplay muted loop>
                            <source src="static/videos/real_world/sort_obj_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-ender">
                        <video id="ender" autoplay muted loop>
                            <source src="static/videos/real_world/open_jar_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                    <!--<div class="item item-kirby">
                        <video id="kirby" autoplay muted loop>
                            <source src="static/videos/real_world/pull_knife_filled.mp4" type="video/mp4">
                        </video>
                    </div>-->
                    <div class="item item-pokemon">
                        <video id="pokemon" autoplay muted loop>
                            <source src="static/videos/real_world/set_dice_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-chansey">
                        <video id="chansey" autoplay muted loop>
                            <source src="static/videos/real_world/close_laptop_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-pikachu">
                        <video id="pikachu" autoplay muted loop>
                            <source src="static/videos/real_world/press_switch_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- /Real-world Results -->

    <!-- Simulation generated data -->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <br/>
                        <br/>
                        <h2 class="title is-3">Simulation</h2>
                        <div class="columns">
                            <div class="column has-text-centered">
                                <h3 class="title is-5">Generated data</h3>
                                Method
                                <div class="select is-small">
                                    <select id="single-menu-methods" onchange="updateSimulationGeneratedDataVideo()">
                                        <option value="manipulate_anything" selected="selected">Manipulate Anything</option>
                                        <option value="voxposer">Voxposer</option>
                                        <option value="code_as_policies">Code as policies</option>
                                        <option value="scaling_up">Scaling Up</option>
                                        <option value="rlbench">Rlbench</option>
                                    </select>
                                </div>
                                applied to task
                                <div class="select is-small">
                                    <select id="single-menu-tasks" onchange="updateSimulationGeneratedDataVideo()">
                                        <option value="play_jenga_mod" selected="selected">play jenga mod.</option>
                                        <option value="slide_block_mod">slide block mod.</option>
                                        <option value="pick_and_lift">pick and lift</option>
                                        <option value="close_box">close box</option>
                                        <option value="lamp_on">lamp on</option>
                                        <option value="open_box">open box</option>
                                        <option value="open_jar">open jar</option>
                                        <option value="open_wine">open wine</option>
                                        <option value="pick_up_cup">pick up cup</option>
                                        <option value="play_jenga">play jenga</option>
                                        <option value="put_block">put block</option>
                                        <option value="put_knife">put knife</option>
                                        <option value="sort_mustard">sort mustard</option>
                                        <option value="take_umbrella">take umbrella</option>
                                    </select>
                                </div>
                                <br/>
                                <br/>
                                <video id="simulation-result-video" muted autoplay loop>
                                    <source src="static/videos/simulation/manipulate_anything/pick_and_lift.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- /Simulation generated data -->

    <!-- Simulation PERACT training -->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <div class="columns">
                            <div class="column has-text-centered">
                                <h3 class="title is-5">Trained instance of PerAct</h3>
                                Method
                                <div class="select is-small">
                                    <select id="peract-single-menu-methods" onchange="updatePerActTrainedVideo()">
                                        <option value="manipulate_anything" selected="selected">Manipulate Anything</option>
                                        <option value="rlbench">Rlbench</option>
                                        <option value="voxposer">Voxposer</option>
                                        <option value="code_as_policies">Code as Policies</option>
                                    </select>
                                </div>
                                with data for task
                                <div class="select is-small">
                                    <select id="peract-single-menu-tasks" onchange="updatePerActTrainedVideo()">
                                        <option value="pick_and_lift" selected="selected">pick and lift</option>
                                        <option value="close_box">close box</option>
                                        <option value="lamp_on">lamp on</option>
                                        <option value="open_box">open box</option>
                                        <option value="open_jar">open jar</option>
                                        <option value="open_wine">open wine</option>
                                        <option value="pick_up_cup">pick up cup</option>
                                        <option value="play_jenga">play jenga</option>
                                        <option value="put_block">put block</option>
                                        <option value="put_knife">put knife</option>
                                        <option value="sort_mustard">sort mustard</option>
                                        <option value="take_umbrella">take umbrella</option>
                                    </select>
                                </div>
                                <br/>
                                <br/>
                                <video id="peract-simulation-result-video" muted autoplay loop>
                                    <source src="static/videos/simulation_peract/rlbench/pick_and_lift.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- /Simulation PERACT training -->

    <!-- Image MA_Framework -->
    <section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Manipulate-Anything Framework</h2>
                <img src="static/images/img_manipulate_anything_framework.png" />
                <p class="caption">The process begins by inputting a scene representation and a natural language task instruction into a VLM, which identifies objects and determines sub-goals. For each sub-goal, we provide multi-view images, verification conditions, and task goals to the action generation module, producing a task-specific grasp pose or action code. This leads to a temporary goal state, assessed by the sub-goal verification module for error recovery. Once all sub-goals are achieved, we filter the trajectories to obtain successful demonstrations for downstream policy training.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- /Image MA_Framework -->

    <!-- Image MA_Action_Generation_Module -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Action Generation Module</h2>
                    <img src="static/images/img_action_generation_module.png" />
                    <p class="caption">This module enables generation of two types of actions: object-centric and agent centric. For object-centric actions which require manipulation of an object, we leverage a foundation grasp model to generate all suitable grasps. Next, we leverage a VLM to detect the object from mult-view frames, and along with the candidate grasp poses and target subgoal, query the VLM to select the best view point. 
  We filter and select the optimal grasp for the sub-goal. For more agent-centric actions, the view-point selection process is the same, and the goal is to output code representing the change in pose of the end-effector from the current frame.</p>
                </div>
            </div>
        </div>
    </section>
    <!-- /Image MA_Action_Generation_Module -->

    <!-- Image MA_Action_Distribution -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Action Distribution</h2>
                    <img src="static/images/img_action_distribution.png" />
                </div>
            </div>
        </div>
    </section>
    <!-- /Image MA_Action_Distribution -->

</body>
</html>
